{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with scikit-learn - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll learn how to use scikit-learn's implementation of a KNN classifier on the classic Titanic dataset from Kaggle!\n",
    " \n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:\n",
    "\n",
    "- Conduct a parameter search to find the optimal value for K \n",
    "- Use a KNN classifier to generate predictions on a real-world dataset \n",
    "- Evaluate the performance of a KNN model  \n",
    "\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Start by importing the dataset, stored in the `titanic.csv` file, and previewing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_data_path = 'titanic.csv'  # Adjust the path if needed\n",
    "raw_df = pd.read_csv(titanic_data_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(raw_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Next, you'll perform some preprocessing steps such as removing unnecessary columns and normalizing features.\n",
    "\n",
    "## Preprocessing the data\n",
    "\n",
    "Preprocessing is an essential component in any data science pipeline. It's not always the most glamorous task as might be an engaging data visual or impressive neural network, but cleaning and normalizing raw datasets is very essential to produce useful and insightful datasets that form the backbone of all data powered projects. This can include changing column types, as in: \n",
    "\n",
    "\n",
    "```python\n",
    "df['col_name'] = df['col_name'].astype('int')\n",
    "```\n",
    "Or extracting subsets of information, such as: \n",
    "\n",
    "```python\n",
    "import re\n",
    "df['street'] = df['address'].map(lambda x: re.findall('(.*)?\\n', x)[0])\n",
    "```\n",
    "\n",
    "> **Note:** While outside the scope of this particular lesson, **regular expressions** (mentioned above) are powerful tools for pattern matching! See the [regular expressions official documentation here](https://docs.python.org/3.6/library/re.html). \n",
    "\n",
    "Since you've done this before, you should be able to do this quite well yourself without much hand holding by now. In the cells below, complete the following steps:\n",
    "\n",
    "1. Remove unnecessary columns (`'PassengerId'`, `'Name'`, `'Ticket'`, and `'Cabin'`) \n",
    "2. Convert `'Sex'` to a binary encoding, where female is `0` and male is `1` \n",
    "3. Detect and deal with any missing values in the dataset:  \n",
    "    * For `'Age'`, replace missing values with the median age for the dataset  \n",
    "    * For `'Embarked'`, drop the rows that contain missing values\n",
    "4. One-hot encode categorical columns such as `'Embarked'` \n",
    "5. Store the target column, `'Survived'`, in a separate variable and remove it from the DataFrame  \n",
    "\n",
    "While we always want to worry about data leakage, which is why we typically perform the split before the preprocessing, for this data set, we'll do some of the preprocessing first. The reason for this is that some of the values of the variables only have a handful of instances, and we want to make sure we don't lose any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0         0       3    male  22.0      1      0   7.2500        S\n",
      "1         1       1  female  38.0      1      0  71.2833        C\n",
      "2         1       3  female  26.0      0      0   7.9250        S\n",
      "3         1       1  female  35.0      1      0  53.1000        S\n",
      "4         0       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "df = raw_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0         0       3    1  22.0      1      0   7.2500        S\n",
      "1         1       1    0  38.0      1      0  71.2833        C\n",
      "2         1       3    0  26.0      0      0   7.9250        S\n",
      "3         1       1    0  35.0      1      0  53.1000        S\n",
      "4         0       3    1  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Sex' to binary encoding\n",
    "df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display the count of missing values for each column\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing values in 'Age' with the median age\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Verify that there are no missing values in 'Age'\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the 'Embarked' column\n",
    "df = df.dropna(subset=['Embarked'])\n",
    "\n",
    "# Verify that there are no missing values in 'Embarked'\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_Q  Embarked_S\n",
      "0         0       3    1  22.0      1      0   7.2500       False        True\n",
      "1         1       1    0  38.0      1      0  71.2833       False       False\n",
      "2         1       3    0  26.0      0      0   7.9250       False        True\n",
      "3         1       1    0  35.0      1      0  53.1000       False        True\n",
      "4         0       3    1  35.0      0      0   8.0500       False        True\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'Embarked' column\n",
    "one_hot_df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(one_hot_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "Features:\n",
      "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_Q  Embarked_S\n",
      "0       3    1  22.0      1      0   7.2500       False        True\n",
      "1       1    0  38.0      1      0  71.2833       False       False\n",
      "2       3    0  26.0      0      0   7.9250       False        True\n",
      "3       1    0  35.0      1      0  53.1000       False        True\n",
      "4       3    1  35.0      0      0   8.0500       False        True\n"
     ]
    }
   ],
   "source": [
    "# Assign the 'Survived' column to labels\n",
    "labels = one_hot_df['Survived']\n",
    "\n",
    "# Drop the 'Survived' column from one_hot_df\n",
    "one_hot_df = one_hot_df.drop(columns=['Survived'])\n",
    "\n",
    "# Verify that the 'Survived' column has been separated\n",
    "print(\"Labels:\")\n",
    "print(labels.head())\n",
    "print(\"\\nFeatures:\")\n",
    "print(one_hot_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets\n",
    "\n",
    "Now that you've preprocessed the data, it's time to split it into training and test sets. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Import `train_test_split` from the `sklearn.model_selection` module \n",
    "* Use `train_test_split()` to split the data into training and test sets, with a `test_size` of `0.25`. Set the `random_state` to 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (711, 8)\n",
      "X_test shape: (178, 8)\n",
      "y_train shape: (711,)\n",
      "y_test shape: (178,)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    one_hot_df, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Verify the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data\n",
    "\n",
    "The final step in your preprocessing efforts for this lab is to **_normalize_** the data. We normalize **after** splitting our data into training and test sets. This is to avoid information \"leaking\" from our test set into our training set (read more about data leakage [here](https://machinelearningmastery.com/data-leakage-machine-learning/) ). Remember that normalization (also sometimes called **_Standardization_** or **_Scaling_**) means making sure that all of your data is represented at the same scale. The most common way to do this is to convert all numerical values to z-scores. \n",
    "\n",
    "Since KNN is a distance-based classifier, if data is in different scales, then larger scaled features have a larger impact on the distance between points.\n",
    "\n",
    "To scale your data, use `StandardScaler` found in the `sklearn.preprocessing` module. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Import and instantiate `StandardScaler` \n",
    "* Use the scaler's `.fit_transform()` method to create a scaled version of the training dataset  \n",
    "* Use the scaler's `.transform()` method to create a scaled version of the test dataset  \n",
    "* The result returned by `.fit_transform()` and `.transform()` methods will be numpy arrays, not a pandas DataFrame. Create a new pandas DataFrame out of this object called `scaled_df`. To set the column names back to their original state, set the `columns` parameter to `one_hot_df.columns` \n",
    "* Print the head of `scaled_df` to ensure everything worked correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass       Sex       Age     SibSp     Parch      Fare  Embarked_Q  \\\n",
      "0 -1.584104 -1.405310 -0.571868 -0.474516 -0.475644  2.430597   -0.317205   \n",
      "1  0.812275 -1.405310 -0.115088  0.381780 -0.475644 -0.358135   -0.317205   \n",
      "2  0.812275  0.711587  0.189432 -0.474516 -0.475644 -0.490949   -0.317205   \n",
      "3  0.812275 -1.405310 -0.115088  6.375852  2.010994  0.762595   -0.317205   \n",
      "4  0.812275  0.711587 -1.180908  3.806964  2.010994  0.301860   -0.317205   \n",
      "\n",
      "   Embarked_S  \n",
      "0    0.619087  \n",
      "1   -1.615282  \n",
      "2    0.619087  \n",
      "3    0.619087  \n",
      "4    0.619087  \n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set, and transform the test set\n",
    "scaled_data_train = scaler.fit_transform(X_train)\n",
    "scaled_data_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled training data into a DataFrame\n",
    "scaled_df_train = pd.DataFrame(scaled_data_train, columns=X_train.columns)\n",
    "\n",
    "# Display the first few rows of the scaled training DataFrame\n",
    "print(scaled_df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the scaler also scaled our binary/one-hot encoded columns, too! Although it doesn't look as pretty, this has no negative effect on the model. Each 1 and 0 have been replaced with corresponding decimal values, but each binary column still only contains 2 values, meaning the overall information content of each column has not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a KNN model\n",
    "\n",
    "Now that you've preprocessed the data it's time to train a KNN classifier and validate its accuracy. \n",
    "\n",
    "In the cells below:\n",
    "\n",
    "* Import `KNeighborsClassifier` from the `sklearn.neighbors` module \n",
    "* Instantiate the classifier. For now, you can just use the default parameters  \n",
    "* Fit the classifier to the training data/labels\n",
    "* Use the classifier to generate predictions on the test data. Store these predictions inside the variable `test_preds` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions:\n",
      "[0 1 1 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)  # Using k=5 as an example\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "clf.fit(scaled_data_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "test_preds = clf.predict(scaled_data_test)\n",
    "\n",
    "# Display the first few predictions\n",
    "print(\"Test Predictions:\")\n",
    "print(test_preds[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Now, in the cells below, import all the necessary evaluation metrics from `sklearn.metrics` and complete the `print_metrics()` function so that it prints out **_Precision, Recall, Accuracy, and F1-Score_** when given a set of `labels` (the true values) and `preds` (the models predictions). \n",
    "\n",
    "Finally, use `print_metrics()` to print the evaluation metrics for the test predictions stored in `test_preds`, and the corresponding labels in `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.7222222222222222\n",
      "Recall Score: 0.7536231884057971\n",
      "Accuracy Score: 0.7921348314606742\n",
      "F1 Score: 0.7375886524822695\n"
     ]
    }
   ],
   "source": [
    "# Complete the function\n",
    "def print_metrics(labels, preds):\n",
    "    from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "    \n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds)))\n",
    "\n",
    "# Use the function to print metrics for the test predictions\n",
    "print_metrics(y_test, test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interpret each of the metrics above, and explain what they tell you about your model's capabilities. If you had to pick one score to best describe the performance of the model, which would you choose? Explain your answer.\n",
    "\n",
    "Write your answer below this line: \n",
    "\n",
    "\n",
    "________________________________________________________________________________\n",
    "\n",
    "Let’s break down the metrics and interpret each one in the context of your KNN model's performance:\n",
    "\n",
    "---\n",
    "\n",
    "### **Metric Interpretations**:\n",
    "\n",
    "1. **Precision Score: 0.722**\n",
    "   - Precision measures the proportion of positive predictions that were actually correct. \n",
    "   - **Interpretation**: Out of all the passengers predicted to survive, 72.2% actually survived. \n",
    "   - **Significance**: This metric is important when the cost of false positives (e.g., predicting survival when the passenger didn’t survive) is high.\n",
    "\n",
    "2. **Recall Score: 0.754**\n",
    "   - Recall (also known as sensitivity) measures the proportion of actual positives correctly identified.\n",
    "   - **Interpretation**: The model correctly identified 75.4% of the passengers who actually survived.\n",
    "   - **Significance**: Recall is critical when the cost of false negatives (e.g., failing to predict survival when the passenger actually survived) is high.\n",
    "\n",
    "3. **Accuracy Score: 0.792**\n",
    "   - Accuracy measures the proportion of correct predictions (both positives and negatives) out of all predictions.\n",
    "   - **Interpretation**: The model correctly predicted survival or non-survival for 79.2% of passengers.\n",
    "   - **Significance**: Accuracy is a general metric but may not be reliable in datasets with class imbalance.\n",
    "\n",
    "4. **F1 Score: 0.738**\n",
    "   - The F1 Score is the harmonic mean of precision and recall, balancing both metrics.\n",
    "   - **Interpretation**: The F1 Score of 73.8% reflects a balance between the precision and recall of the model.\n",
    "   - **Significance**: F1 is particularly useful when the dataset has an imbalance between classes (e.g., more non-survivors than survivors).\n",
    "\n",
    "---\n",
    "\n",
    "### **Which Metric Best Describes the Model?**\n",
    "\n",
    "- If **class imbalance** exists in the dataset (e.g., significantly more non-survivors than survivors), **F1 Score** is the most reliable metric. It balances precision and recall, providing a holistic view of the model's performance.\n",
    "- If the **cost of false negatives** is high (e.g., missing survivors is critical), **Recall** might be more critical.\n",
    "- If the **cost of false positives** is high (e.g., incorrectly identifying survivors is costly), **Precision** would be more important.\n",
    "\n",
    "**Recommendation**: If I had to pick one score to best describe the performance of the model, I would choose the **F1 Score (0.738)** because it balances both precision and recall, providing a comprehensive measure of the model's ability to correctly identify survivors while minimizing false positives and false negatives, which is crucial in datasets with potential class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model performance\n",
    "\n",
    "While your overall model results should be better than random chance, they're probably mediocre at best given that you haven't tuned the model yet. For the remainder of this notebook, you'll focus on improving your model's performance. Remember that modeling is an **_iterative process_**, and developing a baseline out of the box model such as the one above is always a good start. \n",
    "\n",
    "First, try to find the optimal number of neighbors to use for the classifier. To do this, complete the `find_best_k()` function below to iterate over multiple values of K and find the value of K that returns the best overall performance. \n",
    "\n",
    "The function takes in six arguments:\n",
    "* `X_train`\n",
    "* `y_train`\n",
    "* `X_test`\n",
    "* `y_test`\n",
    "* `min_k` (default is 1)\n",
    "* `max_k` (default is 25)\n",
    "    \n",
    "> **Pseudocode Hint**:\n",
    "1. Create two variables, `best_k` and `best_score`\n",
    "1. Iterate through every **_odd number_** between `min_k` and `max_k + 1`. \n",
    "    1. For each iteration:\n",
    "        1. Create a new `KNN` classifier, and set the `n_neighbors` parameter to the current value for k, as determined by the loop \n",
    "        1. Fit this classifier to the training data \n",
    "        1. Generate predictions for `X_test` using the fitted classifier \n",
    "        1. Calculate the **_F1-score_** for these predictions \n",
    "        1. Compare this F1-score to `best_score`. If better, update `best_score` and `best_k` \n",
    "1. Once all iterations are complete, print the best value for k and the F1-score it achieved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=1, max_k=25):\n",
    "    # Initialize variables to track the best k and its corresponding F1 score\n",
    "    best_k = None\n",
    "    best_score = 0\n",
    "\n",
    "    # Iterate through odd numbers between min_k and max_k + 1\n",
    "    for k in range(min_k, max_k + 1, 2):  # Only odd numbers\n",
    "        # Create and fit the KNN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Generate predictions on the test set\n",
    "        preds = knn.predict(X_test)\n",
    "\n",
    "        # Calculate the F1 score\n",
    "        current_score = f1_score(y_test, preds)\n",
    "\n",
    "        # Update best_k and best_score if current_score is better\n",
    "        if current_score > best_score:\n",
    "            best_k = k\n",
    "            best_score = current_score\n",
    "\n",
    "    # Print the best k and its corresponding F1 score\n",
    "    print(f\"Best K: {best_k}\")\n",
    "    print(f\"Best F1 Score: {best_score:.2f}\")\n",
    "\n",
    "    return best_k, best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 21\n",
      "Best F1 Score: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 0.7575757575757576)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_k(scaled_data_train, y_train, scaled_data_test, y_test)\n",
    "# Expected Output:\n",
    "\n",
    "# Best Value for k: 17\n",
    "# F1-Score: 0.7468354430379746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, you'll notice that model performance has improved by 3 percent by finding an optimal value for k. For further tuning, you can use scikit-learn's built-in `GridSearch()` to perform a similar exhaustive check of hyperparameter combinations and fine tune model performance. For a full list of model parameters, see the [sklearn documentation !](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "\n",
    "\n",
    "## (Optional) Level Up: Iterating on the data\n",
    "\n",
    "As an optional (but recommended!) exercise, think about the decisions you made during the preprocessing steps that could have affected the overall model performance. For instance, you were asked to replace the missing age values with the column median. Could this have affected the overall performance? How might the model have fared if you had just dropped those rows, instead of using the column median? What if you reduced the data's dimensionality by ignoring some less important columns altogether?\n",
    "\n",
    "In the cells below, revisit your preprocessing stage and see if you can improve the overall results of the classifier by doing things differently. Consider dropping certain columns, dealing with missing values differently, or using an alternative scaling function. Then see how these different preprocessing techniques affect the performance of the model. Remember that the `find_best_k()` function handles all of the fitting; use this to iterate quickly as you try different strategies for dealing with data preprocessing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you worked with the classic Titanic dataset and practiced fitting and tuning KNN classification models using scikit-learn! As always, this gave you another opportunity to continue practicing your data wrangling skills and model tuning skills using Pandas and scikit-learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
